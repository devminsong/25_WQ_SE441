@startuml
participant "main.py" as Main
participant "tutorial.py" as Tutorial
participant "Gymnasium Env" as Env

Main -> Env: generate_env() : gym.make()
activate Env
activate Main
Env --> Main: env object
deactivate Env

== Part 1: Generate and Evaluate Random Policies ==
Main -> Tutorial: generate_random_policy(seed)
activate Tutorial
Tutorial --> Main: policy object
deactivate Tutorial

== Part 2: Calculate Optimal Policy using Value Iteration ==
Main -> Main: value_iteration(env)
activate Main
Main -> Main: calculate V and optimal policy based on env.P
Main --> Main: returns V, optimal_policy
deactivate Main

== Policy Evaluation (Common for Part 1 & Part 2) ==
Main -> Main: evaluate_policy(env, policy, num_experiments, num_episodes_per_experiment)
activate Main
loop Loop num_experiments times
  Main -> Tutorial: run_one_experiment(env, policy, num_episodes)
  activate Tutorial
  loop Loop num_episodes times
    Tutorial -> Env: reset()
    activate Env
    Env --> Tutorial: initial state
    deactivate Env
    loop Loop until episode ends (done)
      Tutorial -> Env: step(action) using policy[state]
      activate Env
      Env --> Tutorial: next_state, reward, done, info, p
      deactivate Env
    end
  end
  Tutorial --> Main: goals, holes, total_rewards, total_goal_steps
  deactivate Tutorial
end
Main --> Main: returns goals_list, mean_total_goal_steps_list
deactivate Main

== Display and Save Results (Common for Part 1 & Part 2) ==
Main -> Tutorial: display_policy(policy, n_states)
activate Tutorial
Tutorial --> Main: formatted policy string
deactivate Tutorial
Main -> Main: print(formatted policy)
Main -> Main: display_formatted_policy(V, nS)
Main -> Main: print(formatted V table)
Main -> Main: generate_csv(data_rows, filename, header)
activate Main
Main --> Main: save data to CSV
deactivate Main

Main -> Env: env.close()
activate Env
deactivate Env
deactivate Main

@enduml

' @startuml
' participant "main.py" as Main
' participant "tutorial.py" as Tutorial
' participant "Gymnasium Env" as Env

' Main -> Env: generate_env() : gym.make()
' activate Env
' activate Main
' Env --> Main: env object
' deactivate Env

' == Part 1: 랜덤 정책 생성 및 평가 ==
' Main -> Tutorial: generate_random_policy(seed)
' activate Tutorial
' Tutorial --> Main: policy object
' deactivate Tutorial

' == Part 2: 가치 반복으로 최적 정책 계산 ==
' Main -> Main: value_iteration(env)
' activate Main
' Main -> Main: calculate V and optimal policy based on env.P
' Main --> Main: returns V, optimal_policy
' deactivate Main

' == 정책 평가 (Part 1 & Part 2 공통) ==
' Main -> Main: evaluate_policy(env, policy, num_experiments, num_episodes_per_experiment)
' activate Main
' loop num_experiments 회 반복
'   Main -> Tutorial: run_one_experiment(env, policy, num_episodes)
'   activate Tutorial
'   loop num_episodes 회 반복
'     Tutorial -> Env: reset()
'     activate Env
'     Env --> Tutorial: initial state
'     deactivate Env
'     loop 에피소드 종료까지 (done)
'       Tutorial -> Env: step(action) using policy[state]
'       activate Env
'       Env --> Tutorial: next_state, reward, done, info, p
'       deactivate Env
'     end
'   end
'   Tutorial --> Main: goals, holes, total_rewards, total_goal_steps
'   deactivate Tutorial
' end
' Main --> Main: returns goals_list, mean_total_goal_steps_list
' deactivate Main

' == 결과 표시 및 저장 (Part 1 & Part 2 공통) ==
' Main -> Tutorial: display_policy(policy, n_states)
' activate Tutorial
' Tutorial --> Main: formatted policy string
' deactivate Tutorial
' Main -> Main: print(formatted policy)
' Main -> Main: display_formatted_policy(V, nS)
' Main -> Main: print(formatted V table)
' Main -> Main: generate_csv(data_rows, filename, header)
' activate Main
' Main --> Main: save data to CSV
' deactivate Main

' Main -> Env: env.close()
' activate Env
' deactivate Env
' deactivate Main

' @enduml